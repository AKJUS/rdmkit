---
title: Analysing
keywords: [Data analysis, Computing, Collaboration]
contributors: [Rob Hooft, Olivier Collin]
---

## What is Data Analysis?

Data analysis encompasses all the different data manipulation and transformations that will help scientists to discover information or generate new knowledge.
This is the step where the actual work on the data towards the goal of a research project takes place.
The steps of the workflow in the Analysis phase of a project will often be repeated several times to explore the data as well as to optimize the process.
According to the different types of data (quantitative or qualitative) the methods will differ.

Data analysis follows the (often automated, batch) processing in the Processing stage.

## Why is Data Analysis important?

Since it is the stage where new knowledge and information are generated, it can be considered as central in the research process.
With many disciplines becoming data-oriented, more and more data intensive projects will occur and will involve experts from many thematic fields.

## What should be considered for Data Analysis?

Because of their nature, data in Life Sciences are now considered as Big Data. These characteristics of Big Data, often summarized by a growing list of "V" properties (Volume, Velocity, Variety, Veracity, Value, etc.), impact strongly the methods and technical solutions used for Data Analysis.

* By its volume and velocity, data generated in Life Sciences, create a challenge that has to be addressed at several levels. At the storage level, including the transfer of the data from the data production facility to the computing facility for its analysis. It is sometimes worth to consider the cost of the transfer of massive amounts of data compared to the transfer of virtual images of machines for the analysis of the data.
* The variety of the data poses an integration challenge that can only adressed with the help of best practices that make data interoperable and reusable.
* The Data Analysis phase relies on the previous steps (collection, processing) that will lay the foundations for the generation of new knowledge by providing acurate and trustworthy data.

## Problems to be addressed at this stage

* Computational environment : For the analysis of their data, scientists will first have to consider the computing environment and choose between several computing infrastructure types : cluster, cloud. They also have to select their work environment according to their needs and expertise (command line, web portal).
* Storage environment : The location of the data is important because of the needed proximity with computing resources. This can imply data transfer accross the different infrastructures.
* Tools :  Scientists will have to select the tools best suited for the analysis of their data. Resources such as [bio.tools](https://bio.tools) can be very helpful.
* Reproducibility : It is important that the exact steps that have been taken in the data analysis are documented. This includes the version of the software used, as well as the parameters used, but also the computing environment. Manual "manipulation" of the data may complicate this documentation process.
* Collaboration : In the case of collaborative data analysis, scientists and support teams will have to ensure access to the data and tools for all collaborators. This can be achieved by setting up virtual research environments (VRE). 


## Where can training materials and events about Data Analysis be found?

{% include tess.html search="Data Analysis" %}

## Related topics

{% include pagelist.html tag="analyse" %}

<!-- ## External links
missing content -->
